{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam/ham_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2zJmRfhBXLN",
        "colab_type": "code",
        "outputId": "449177f8-26fa-4710-a9e4-14605204511c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set(style = \"whitegrid\", \n",
        "        color_codes = True,\n",
        "        font_scale = 1.5)\n",
        "from keras.models import load_model, Model\n",
        "from keras.layers import SimpleRNN, Dense, Input, Dropout, LSTM, Activation, Embedding, Bidirectional\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiXgK2LtMvKa",
        "colab_type": "code",
        "outputId": "800b7f5b-3aab-48bb-a0d2-411316bc77d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install beautifulsoup4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsoXRMKe_nAq",
        "colab_type": "code",
        "outputId": "f3647823-23a7-4468-e236-fe6e81f03694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MmkjoaXCRHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in data from CSV\n",
        "original_training_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/train.csv')\n",
        "evaluation = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/eval.csv')\n",
        "\n",
        "# Convert the emails to lower case as a first step to processing the text\n",
        "original_training_data['email'] = original_training_data['email'].str.lower()\n",
        "evaluation['email'] = evaluation['email'].str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2PPiLR3Bp7m",
        "colab_type": "code",
        "outputId": "f36c7245-ad20-428b-b79a-59a5f20632f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# View the CSV\n",
        "original_training_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>subject</th>\n",
              "      <th>email</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Subject: A&amp;L Daily to be auctioned in bankrupt...</td>\n",
              "      <td>url: http://boingboing.net/#85534171\\n date: n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Subject: Wired: \"Stronger ties between ISPs an...</td>\n",
              "      <td>url: http://scriptingnews.userland.com/backiss...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Subject: It's just too small                  ...</td>\n",
              "      <td>&lt;html&gt;\\n &lt;head&gt;\\n &lt;/head&gt;\\n &lt;body&gt;\\n &lt;font siz...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Subject: liberal defnitions\\n</td>\n",
              "      <td>depends on how much over spending vs. how much...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Subject: RE: [ILUG] Newbie seeks advice - Suse...</td>\n",
              "      <td>hehe sorry but if you hit caps lock twice the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... spam\n",
              "0   0  ...    0\n",
              "1   1  ...    0\n",
              "2   2  ...    1\n",
              "3   3  ...    0\n",
              "4   4  ...    0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWDGEPssBq58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[train, test] = train_test_split(original_training_data, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "askC5WswYpIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "def remove_stopwords(x):\n",
        "  word_tokens = word_tokenize(x) \n",
        "  filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
        "  return ' '.join(filtered_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE2glvAcG4fG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data(data):\n",
        "  df = data.copy()\n",
        "  df['subject'] = data['subject'].fillna(\"\")\n",
        "  df['subject'] = df['subject'].str.replace(\"Subject:\", \"\", regex=False)\n",
        "  df['email'] = df['email'].apply(lambda x: BeautifulSoup(x).get_text())\n",
        "  df['email'] = df['email'].apply(lambda x: x.strip())\n",
        "  df['email'] = df['email'].apply(remove_stopwords)\n",
        "  return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXBeIEBiGO0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_train = clean_data(train)\n",
        "clean_test = clean_data(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppdP9_CWaF-a",
        "colab_type": "code",
        "outputId": "ff1197fb-7879-4a32-f604-2b9477923b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clean_train.email.map(len).max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "299735"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFfXEgw_DVwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_sentences = clean_train['email'].to_numpy()\n",
        "training_labels = clean_train['spam'].to_numpy()\n",
        "\n",
        "testing_sentences = clean_test['email'].to_numpy()\n",
        "testing_labels = clean_test['spam'].to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15pqDGj-DTrB",
        "colab_type": "code",
        "outputId": "4202a2fe-c631-4e02-e892-9f1036df429c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "vocab_size = 500 # only the top 500 most frequent words\n",
        "embedding_dim = 100\n",
        "max_length = 500\n",
        "trunc_type = 'post'\n",
        "oov_tok = '<OOV>'\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "# Dictionary mapping words to their index\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded = pad_sequences(sequences, maxlen = max_length, truncating = trunc_type)\n",
        "\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(test_sequences, maxlen = max_length, truncating = trunc_type)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 102506 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uBJR3I1GfRB",
        "colab_type": "text"
      },
      "source": [
        "Lets examine the words that the tokenization found.\n",
        "Unfortunately, due to the way tokenization works, word_index contains tokens for all unique words, despite our vocab_size. When we use tokenizer later to token our text, only the most common vocab_size (500) words will be used. \n",
        "So for now, as a quick solution, we can filter the words by index to get the most frequent words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTxNttyxDRAr",
        "colab_type": "code",
        "outputId": "9624917c-b094-4d3c-bd91-649fc37074d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for word, index in word_index.items():\n",
        "  if index < vocab_size + 1:\n",
        "    print (word, index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<OOV> 1\n",
            "e 2\n",
            "n 3\n",
            "'' 4\n",
            "r 5\n",
            "1 6\n",
            "0 7\n",
            "http 8\n",
            "com 9\n",
            "c 10\n",
            "'s 11\n",
            "09 12\n",
            "l 13\n",
            "f 14\n",
            "h 15\n",
            "20 16\n",
            "p 17\n",
            "2 18\n",
            "w 19\n",
            "www 20\n",
            "b 21\n",
            "n't 22\n",
            "g 23\n",
            "list 24\n",
            "net 25\n",
            "2002 26\n",
            "3 27\n",
            "one 28\n",
            "get 29\n",
            "u 30\n",
            "email 31\n",
            "5 32\n",
            "' 33\n",
            "linux 34\n",
            "free 35\n",
            "new 36\n",
            "4 37\n",
            "mail 38\n",
            "time 39\n",
            "use 40\n",
            "lists 41\n",
            "would 42\n",
            "people 43\n",
            "like 44\n",
            "000 45\n",
            "click 46\n",
            "3d 47\n",
            "html 48\n",
            "v 49\n",
            "content 50\n",
            "us 51\n",
            "font 52\n",
            "3e 53\n",
            "6 54\n",
            "listinfo 55\n",
            "information 56\n",
            "users 57\n",
            "7 58\n",
            "d 59\n",
            "00 60\n",
            "message 61\n",
            "8 62\n",
            "please 63\n",
            "10 64\n",
            "also 65\n",
            "text 66\n",
            "make 67\n",
            "mailing 68\n",
            "k 69\n",
            "color 70\n",
            "business 71\n",
            "spamassassin 72\n",
            "x 73\n",
            "9 74\n",
            "ie 75\n",
            "web 76\n",
            "mailman 77\n",
            "0d 78\n",
            "org 79\n",
            "money 80\n",
            "z 81\n",
            "want 82\n",
            "could 83\n",
            "see 84\n",
            "work 85\n",
            "wrote 86\n",
            "first 87\n",
            "may 88\n",
            "exmh 89\n",
            "software 90\n",
            "way 91\n",
            "address 92\n",
            "internet 93\n",
            "'m 94\n",
            "rpm 95\n",
            "world 96\n",
            "'ve 97\n",
            "know 98\n",
            "size 99\n",
            "sourceforge 100\n",
            "even 101\n",
            "send 102\n",
            "type 103\n",
            "need 104\n",
            "said 105\n",
            "system 106\n",
            "home 107\n",
            "date 108\n",
            "news 109\n",
            "name 110\n",
            "spam 111\n",
            "much 112\n",
            "22 113\n",
            "using 114\n",
            "find 115\n",
            "razor 116\n",
            "go 117\n",
            "many 118\n",
            "well 119\n",
            "right 120\n",
            "company 121\n",
            "3c 122\n",
            "think 123\n",
            "url 124\n",
            "s 125\n",
            "'ll 126\n",
            "'re 127\n",
            "good 128\n",
            "file 129\n",
            "group 130\n",
            "help 131\n",
            "50 132\n",
            "family 133\n",
            "ca 134\n",
            "site 135\n",
            "report 136\n",
            "line 137\n",
            "today 138\n",
            "8p 139\n",
            "receive 140\n",
            "best 141\n",
            "take 142\n",
            "subject 143\n",
            "order 144\n",
            "https 145\n",
            "years 146\n",
            "windows 147\n",
            "a 148\n",
            "read 149\n",
            "check 150\n",
            "day 151\n",
            "q 152\n",
            "ilug 153\n",
            "back 154\n",
            "service 155\n",
            "phone 156\n",
            "sf 157\n",
            "still 158\n",
            "two 159\n",
            "link 160\n",
            "change 161\n",
            "every 162\n",
            "year 163\n",
            "unsubscribe 164\n",
            "program 165\n",
            "government 166\n",
            "online 167\n",
            "used 168\n",
            "security 169\n",
            "set 170\n",
            "fork 171\n",
            "version 172\n",
            "redhat 173\n",
            "server 174\n",
            "01 175\n",
            "without 176\n",
            "12 177\n",
            "top 178\n",
            "j 179\n",
            "since 180\n",
            "yahoo 181\n",
            "life 182\n",
            "data 183\n",
            "really 184\n",
            "sent 185\n",
            "last 186\n",
            "computer 187\n",
            "100 188\n",
            "end 189\n",
            "available 190\n",
            "de 191\n",
            "something 192\n",
            "files 193\n",
            "million 194\n",
            "say 195\n",
            "code 196\n",
            "made 197\n",
            "perl 198\n",
            "subscription 199\n",
            "11 200\n",
            "sure 201\n",
            "transfer 202\n",
            "number 203\n",
            "cd 204\n",
            "next 205\n",
            "better 206\n",
            "part 207\n",
            "look 208\n",
            "long 209\n",
            "talk 210\n",
            "remove 211\n",
            "old 212\n",
            "services 213\n",
            "co 214\n",
            "real 215\n",
            "support 216\n",
            "messages 217\n",
            "state 218\n",
            "full 219\n",
            "run 220\n",
            "'d 221\n",
            "problem 222\n",
            "price 223\n",
            "form 224\n",
            "within 225\n",
            "id 226\n",
            "based 227\n",
            "high 228\n",
            "never 229\n",
            "states 230\n",
            "freshrpms 231\n",
            "another 232\n",
            "must 233\n",
            "technology 234\n",
            "30 235\n",
            "call 236\n",
            "i 237\n",
            "easy 238\n",
            "great 239\n",
            "anyone 240\n",
            "companies 241\n",
            "week 242\n",
            "uk 243\n",
            "got 244\n",
            "weight 245\n",
            "user 246\n",
            "removed 247\n",
            "offer 248\n",
            "access 249\n",
            "page 250\n",
            "give 251\n",
            "start 252\n",
            "try 253\n",
            "future 254\n",
            "going 255\n",
            "found 256\n",
            "received 257\n",
            "t 258\n",
            "nextpart 259\n",
            "network 260\n",
            "market 261\n",
            "info 262\n",
            "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii 263\n",
            "encoding 264\n",
            "product 265\n",
            "case 266\n",
            "per 267\n",
            " 268\n",
            "might 269\n",
            "open 270\n",
            "small 271\n",
            "pj4 272\n",
            "search 273\n",
            "keep 274\n",
            "microsoft 275\n",
            "02 276\n",
            "things 277\n",
            "xent 278\n",
            "charset 279\n",
            "25 280\n",
            "15 281\n",
            "different 282\n",
            "18 283\n",
            "sponsored 284\n",
            "united 285\n",
            "un 286\n",
            "looking 287\n",
            "a3 288\n",
            "following 289\n",
            "example 290\n",
            "decoration 291\n",
            "credit 292\n",
            "times 293\n",
            "23 294\n",
            "thinkgeek 295\n",
            "days 296\n",
            "products 297\n",
            "let 298\n",
            "normal 299\n",
            "background 300\n",
            "story 301\n",
            "less 302\n",
            "ever 303\n",
            "wish 304\n",
            "latest 305\n",
            "marketing 306\n",
            "irish 307\n",
            "08 308\n",
            "tech 309\n",
            "etc 310\n",
            "24 311\n",
            "thing 312\n",
            "come 313\n",
            "thanks 314\n",
            "save 315\n",
            "source 316\n",
            "face 317\n",
            "around 318\n",
            "article 319\n",
            "put 320\n",
            "someone 321\n",
            "signature 322\n",
            "systems 323\n",
            "actually 324\n",
            "issue 325\n",
            "original 326\n",
            "card 327\n",
            "contact 328\n",
            "build 329\n",
            "yes 330\n",
            "month 331\n",
            "cnet 332\n",
            "special 333\n",
            "however 334\n",
            "21 335\n",
            "asp 336\n",
            "reply 337\n",
            "works 338\n",
            "legal 339\n",
            "2e 340\n",
            "release 341\n",
            "package 342\n",
            "rights 343\n",
            "public 344\n",
            "apt 345\n",
            "b5 346\n",
            "in 347\n",
            "show 348\n",
            "always 349\n",
            "ac 350\n",
            "inc 351\n",
            "sep 352\n",
            "least 353\n",
            "point 354\n",
            "little 355\n",
            "addresses 356\n",
            "visit 357\n",
            "instead 358\n",
            "buy 359\n",
            "media 360\n",
            "personal 361\n",
            "3cfont 362\n",
            "2ffont 363\n",
            "problems 364\n",
            "error 365\n",
            "though 366\n",
            "add 367\n",
            "working 368\n",
            "none 369\n",
            "pgp 370\n",
            "application 371\n",
            "probably 372\n",
            "plain 373\n",
            "maintainer 374\n",
            "already 375\n",
            "mr 376\n",
            "stuff 377\n",
            "lot 378\n",
            "place 379\n",
            "running 380\n",
            "bb 381\n",
            "non 382\n",
            "listmaster 383\n",
            "sites 384\n",
            "says 385\n",
            "99 386\n",
            "cost 387\n",
            "workers 388\n",
            "19 389\n",
            "low 390\n",
            "able 391\n",
            "download 392\n",
            "pc 393\n",
            "making 394\n",
            "aug 395\n",
            "including 396\n",
            "kernel 397\n",
            "july 398\n",
            "course 399\n",
            "include 400\n",
            "current 401\n",
            "simple 402\n",
            "programs 403\n",
            "border 404\n",
            "anything 405\n",
            "copyright 406\n",
            "insurance 407\n",
            "september 408\n",
            "13 409\n",
            "getting 410\n",
            "account 411\n",
            "pm 412\n",
            "cash 413\n",
            "16 414\n",
            "left 415\n",
            "format 416\n",
            "14 417\n",
            "else 418\n",
            "center 419\n",
            "m 420\n",
            "tell 421\n",
            "pay 422\n",
            "three 423\n",
            "to 424\n",
            "hard 425\n",
            "yet 426\n",
            "local 427\n",
            "seems 428\n",
            "financial 429\n",
            "job 430\n",
            "simply 431\n",
            "key 432\n",
            "big 433\n",
            "digital 434\n",
            "grants 435\n",
            "write 436\n",
            "newsletter 437\n",
            "possible 438\n",
            "development 439\n",
            "mailto 440\n",
            "3b 441\n",
            "xml 442\n",
            "ad 443\n",
            "enough 444\n",
            "ms 445\n",
            "groups 446\n",
            "complete 447\n",
            "heaven 448\n",
            "general 449\n",
            "months 450\n",
            "done 451\n",
            "o 452\n",
            "value 453\n",
            "offers 454\n",
            "american 455\n",
            "log 456\n",
            "nbsp 457\n",
            "nothing 458\n",
            "power 459\n",
            "trade 460\n",
            "called 461\n",
            "fax 462\n",
            "country 463\n",
            "root 464\n",
            "daily 465\n",
            "provide 466\n",
            "others 467\n",
            "style 468\n",
            "a1 469\n",
            "results 470\n",
            "box 471\n",
            "via 472\n",
            "law 473\n",
            "website 474\n",
            "folder 475\n",
            "newsisfree 476\n",
            "fact 477\n",
            "book 478\n",
            "trying 479\n",
            "second 480\n",
            "america 481\n",
            "stop 482\n",
            "letter 483\n",
            "mime 484\n",
            "welcome 485\n",
            "iso 486\n",
            "500 487\n",
            "maybe 488\n",
            "solid 489\n",
            "rates 490\n",
            "plus 491\n",
            "bit 492\n",
            "away 493\n",
            "test 494\n",
            "management 495\n",
            "office 496\n",
            "interest 497\n",
            "investment 498\n",
            "august 499\n",
            "policy 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfodBWMOhPmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = {}\n",
        "f = open('/content/drive/My Drive/Colab Notebooks/data/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-hNs0KxhaHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim)) # +1 to account for the <OOV> token\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwNC6gznbucA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            embedding_dim,\n",
        "                            weights = [embedding_matrix],\n",
        "                            input_length = max_length,\n",
        "                            trainable = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHgBjFZAlx6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_mail = Input(shape=(max_length,), dtype='int32')\n",
        "\n",
        "embedded_sequences = embedding_layer(tokenized_mail)\n",
        "x = Bidirectional(LSTM(64, return_sequences = True))(embedded_sequences)\n",
        "# x = Dropout(rate = 0.5 )(x)\n",
        "x = Bidirectional(LSTM(32))(x)\n",
        "# x = Dropout(rate = 0.5 )(x)\n",
        "x = Dense(64, activation = 'relu')(x)\n",
        "# x = Dropout(rate = 0.5 )(x)\n",
        "x = Dense(1, activation = 'sigmoid')(x)\n",
        "\n",
        "model = Model(inputs = tokenized_mail, outputs = x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjH3fHkonuyh",
        "colab_type": "code",
        "outputId": "965ae129-5678-4f39-d85c-abf0519923bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "embedding_7 (Embedding)      (None, 500, 100)          10250700  \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 500, 128)          84480     \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 64)                41216     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 10,380,621\n",
            "Trainable params: 129,921\n",
            "Non-trainable params: 10,250,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x-itfYAnxRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0ccGAjKn1fa",
        "colab_type": "code",
        "outputId": "e2fcc844-f1f9-457e-8666-b318aaea75d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model.fit(padded, \n",
        "          training_labels, \n",
        "          epochs = 5, \n",
        "          batch_size=256,\n",
        "          validation_data = (testing_padded, testing_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7513 samples, validate on 835 samples\n",
            "Epoch 1/5\n",
            "7513/7513 [==============================] - 135s 18ms/step - loss: 0.1115 - acc: 0.9647 - val_loss: 0.1129 - val_acc: 0.9581\n",
            "Epoch 2/5\n",
            "7513/7513 [==============================] - 139s 19ms/step - loss: 0.1019 - acc: 0.9650 - val_loss: 0.1111 - val_acc: 0.9605\n",
            "Epoch 3/5\n",
            "7513/7513 [==============================] - 138s 18ms/step - loss: 0.0934 - acc: 0.9682 - val_loss: 0.1114 - val_acc: 0.9581\n",
            "Epoch 4/5\n",
            "7513/7513 [==============================] - 138s 18ms/step - loss: 0.0872 - acc: 0.9715 - val_loss: 0.1031 - val_acc: 0.9641\n",
            "Epoch 5/5\n",
            "7513/7513 [==============================] - 134s 18ms/step - loss: 0.0828 - acc: 0.9731 - val_loss: 0.1124 - val_acc: 0.9581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe024386710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb6wYmWF4AvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87bv3dyq4FwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSqg7h0GviVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_eval = clean_data(evaluation)\n",
        "eval_sentences = clean_eval['email'].to_numpy()\n",
        "eval_sequences = tokenizer.texts_to_sequences(eval_sentences)\n",
        "eval_padded = pad_sequences(eval_sequences, maxlen = max_length, truncating = trunc_type)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCZ4K6nev3FU",
        "colab_type": "code",
        "outputId": "fa32e6b6-4c11-434a-cd4c-7769d75237b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "clean_eval.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>subject</th>\n",
              "      <th>email</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>CERT Advisory CA-2002-21 Vulnerability in PHP\\n</td>\n",
              "      <td>-- -- -begin pgp signed message -- -- - cert a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ADV: Affordable Life Insurance ddbfk\\n</td>\n",
              "      <td>low-cost term-life insurance ! save 70 % term ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>CAREER OPPORTUNITY.  WORK FROM HOME\\n</td>\n",
              "      <td>-- -- -- =_nextpart_000_00a0_03e30a1a.b1804b54...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Marriage makes both sexes happy\\n</td>\n",
              "      <td>url : http : //www.newsisfree.com/click/-3,848...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Re: [SAtalk] SA very slow (hangs?) on this me...</td>\n",
              "      <td>thursday 29 august 2002 16:39 cet mike burger ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                              email\n",
              "0   0  ...  -- -- -begin pgp signed message -- -- - cert a...\n",
              "1   1  ...  low-cost term-life insurance ! save 70 % term ...\n",
              "2   2  ...  -- -- -- =_nextpart_000_00a0_03e30a1a.b1804b54...\n",
              "3   3  ...  url : http : //www.newsisfree.com/click/-3,848...\n",
              "4   4  ...  thursday 29 august 2002 16:39 cet mike burger ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q4AMlCWv6UO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_labels = model.predict(eval_padded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYUYkVJvxy9X",
        "colab_type": "code",
        "outputId": "3d65abc0-ac61-4a5b-d4e7-dabb06f9dc2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "predicted_labels[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00117591],\n",
              "       [0.99175394],\n",
              "       [0.94528234],\n",
              "       [0.04643938],\n",
              "       [0.00165203]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYPcwk7Pwn61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_predictions = np.where(predicted_labels >= 0.5, 1, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUuCuPZcyJo2",
        "colab_type": "code",
        "outputId": "6ec7318d-53df-45d4-8ee1-0a31e5641638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "evaluation_predictions.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-U-7VVZyr48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_predictions = np.squeeze(evaluation_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgKzvkmOy30z",
        "colab_type": "code",
        "outputId": "8fc1a9d8-c5dc-49ff-aa7c-04cad9b903ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "evaluation_predictions.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMHZzJbZyEVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert isinstance(evaluation_predictions, np.ndarray) \n",
        "\n",
        "# must be binary labels (0 or 1) and not probabilities\n",
        "assert np.all((evaluation_predictions == 0) | (evaluation_predictions == 1))\n",
        "\n",
        "# must be the right number of predictions\n",
        "assert evaluation_predictions.shape == (1000, )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAesizJMySqz",
        "colab_type": "code",
        "outputId": "ae4bad91-9f3d-44a9-f1fa-383be91d04fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Assuming that your predictions on the evaluation set are stored in a 1-dimensional array called\n",
        "# evaluation_predictions. Feel free to modify this cell as long you create a CSV in the right format.\n",
        "\n",
        "# must be ndarray of predictions\n",
        "assert isinstance(evaluation_predictions, np.ndarray) \n",
        "\n",
        "# must be binary labels (0 or 1) and not probabilities\n",
        "assert np.all((evaluation_predictions == 0) | (evaluation_predictions == 1))\n",
        "\n",
        "# must be the right number of predictions\n",
        "assert evaluation_predictions.shape == (1000, )\n",
        "\n",
        "# Construct and save the submission:\n",
        "submission_df = pd.DataFrame({\n",
        "    \"Id\": evaluation['id'], \n",
        "    \"Class\": evaluation_predictions,\n",
        "}, columns=['Id', 'Class'])\n",
        "\n",
        "timestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\n",
        "submission_file_name = \"submission_{}.csv\".format(timestamp)\n",
        "\n",
        "submission_df.to_csv(submission_file_name, index=False)\n",
        "\n",
        "print('Created a CSV file: {}.'.format(submission_file_name))\n",
        "print('You may now upload this CSV file to Kaggle for scoring.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created a CSV file: submission_2020-03-12T22:09:36.csv.\n",
            "You may now upload this CSV file to Kaggle for scoring.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O--xkrDqx67A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(submission_file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUMKIrvzzE_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}